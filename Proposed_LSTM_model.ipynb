{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive for necessary files like dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fy9tRKZYl9oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important variables. This may change as environment changes\n",
        "dataset_path = \"/content/drive/MyDrive/airquality_aam_aca/data/\""
      ],
      "metadata": {
        "id": "IB8QFibsl1dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNw-lgH4oVpJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into the program\n",
        "df = pd.read_csv(dataset_path + \"kolkata.csv\", parse_dates=True)\n",
        "\n",
        "# As the records are collected on daily basis, the index is the date of collection of record\n",
        "df.set_index('date')\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the series, calculate and subtract mean from it\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the mean of whole series to detrend the data\n",
        "mean = np.mean(df.PM25.values)\n",
        "\n",
        "# Following line of code is two step process\n",
        "# i) Subtract mean from each record of dataframe ii) round off each record to 2 precisions\n",
        "data = np.array(list(map(lambda x: round(x, 2), df.PM25.values - mean)))\n",
        "\n",
        "print('===== Original series =====')\n",
        "print(df.PM25.values[:10])\n",
        "\n",
        "print('===== Modified series =====')\n",
        "data = df.PM25.values\n",
        "print(data[:10])"
      ],
      "metadata": {
        "id": "PHNiLGwpoppL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the supervised dataset and reshape it for LSTM model\n",
        "# The utility.py must be uploaded \n",
        "from utility import sequence_to_table\n",
        "\n",
        "# sequence_to_table method converts a list or array into tabular format\n",
        "data = sequence_to_table(data, look_back=30)\n",
        "\n",
        "# divide data into feature and target\n",
        "X = data.drop(columns=['next']).values  # column 'next' is expected outcome of forecast so not a part of features to be trained\n",
        "y = data.next.values\n",
        "\n",
        "# first reshape the data to make it compatible for LSTM\n",
        "X_reshaped = X.reshape((X.shape[0], 1, X.shape[1]))"
      ],
      "metadata": {
        "id": "mwK6xUh9pW5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Model\n",
        "------"
      ],
      "metadata": {
        "id": "bcqk39cvpOXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Proposed LSTM model\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = Sequential(name=\"Proposed_LSTM\")\n",
        "model.add(tf.keras.layers.LSTM(units=512, \n",
        "                              activation='relu', \n",
        "                              input_shape=(1, X_reshaped.shape[2]), return_sequences=True, name=\"input\"))\n",
        "model.add(tf.keras.layers.LSTM(units=512, \n",
        "                              activation='relu', name=\"lstm\"))\n",
        "model.add(tf.keras.layers.Dense(1, name=\"output\"))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "metadata": {
        "id": "D1a92PkfpQVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "AjnRxSu6oA1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_reshaped, y, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "LnwduA_pptRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the loss graph. The loss is represented using RMSE. A graph after training will show you loss decreasing as epochs increases.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5, 3)).set_dpi(128)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ll60tmX-9qz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error as mse, r2_score\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "fitted_values = model.predict(X_reshaped)\n",
        "\n",
        "# Calculate the RMSE with original next values\n",
        "rmse = round(sqrt(mse(y + mean, fitted_values + mean)), 2)\n",
        "r2score = round(r2_score(y + mean, fitted_values + mean), 2)\n",
        "\n",
        "print('RMSE:', rmse)\n",
        "print('R2 Score:', r2score)"
      ],
      "metadata": {
        "id": "Du1_BFsyrgS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot fitted series and original series. There is almost negligible difference in their appearance and nature\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "original = y + mean\n",
        "forecasted = fitted_values + mean\n",
        "\n",
        "plt.figure(figsize=(18, 6)).set_dpi(128)\n",
        "plt.plot(original[-1000:], label='Actual series')\n",
        "plt.plot(forecasted[-1000:], label='Fitted series')\n",
        "plt.legend()\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('PM2.5 Concentration Level')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IWs78kQf71ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the future N values (extrapolation)\n",
        "import numpy as np\n",
        "\n",
        "predictions = []\n",
        "x = X[-1]  # Initially take last training input for predicting its immediate next value\n",
        "\n",
        "for i in range(60):\n",
        "  x = x.reshape((1, 1, X.shape[1]))  # Prepare the input for a tensorflow model using reshaping\n",
        "  prediction = model.predict(x)   # Predict the immediate next value\n",
        "  x = x.ravel()  # Ravel method converts the 3D array to single dimension array \n",
        "  x = np.delete(x, 0)  # Now, we delete first item of the original input\n",
        "  x = np.append(x, prediction[0][0])  # and append the predicted value to use it for next predictions\n",
        "  predictions.append(prediction[0][0])   # append the predicted value to 'predictions' list"
      ],
      "metadata": {
        "id": "jTA-qQjFDEfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions + mean  # Add original mean of the time series into predictions to reveal predictions' original values\n",
        "\n",
        "# Print predictions\n",
        "for i in predictions:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "AdAVksZujwqz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}